---
title: "Assignment 8"
author: "Chase Baggett"
date: "November 9, 2017"
output:
  pdf_document: default
  html_document: default
  github_document: default
---

```{r setup, include=FALSE}
library(alr4)
library(GGally)
library(ggplot2)
```

#8.1

```{r}
model_1 <- lm(lifeExpF ~ 1,data=UN11)
model_2 <- lm(lifeExpF ~ group,data=UN11)
anova(model_1,model_2)
```

#8.2

One model is not a constrained version of the other model. We can do a comparison in this manner between 6.7 or 6.8 and 6.9 or 6.10 because it is possible to constrain the other model to assume a coefficient is equal to zero, but we cannot constrain 6.7 or 6.8 to be equal to each other. 

We can express the t-test as the mean of the sample minus the hypothesized value, over the the standard error expressed as the sample standard deviation divided by the square root of the sample size.
$$t = \frac{\bar{y} - y}{sd / \sqrt{n}}$$
We can also epxress the F test in terms of the standard deviation, sample size, and sample mean.
$$F = \frac{n(\bar{y} - y)^2}{sd^2}$$
If we express them this way, it becomes apparent that $F = t^2$.

#8.3
```{r}
model <- lm(lifeExpF ~ group + log(ppgdp) + group:log(ppgdp), data=UN11)
summary(model)
```

#8.4

First, we fit all of the models.
```{r}
model_1 <- lm(Y ~ X1 + I(X1^2) + X2 + I(X2^2) + X1:X2, data = cakes)
model_2 <- lm(formula = Y ~ X1 + I(X1^2) + X2 + I(X2^2), data = cakes)
model_3 <- lm(formula = Y ~ X1 + X2 + I(X2^2) + X1:X2, data = cakes)
model_4 <- lm(formula = Y ~ X2 + I(X2^2), data = cakes)
```

First Test
We reject the null hypothesis due to the .005 P-Value.
```{r}
anova(model_2,model_1)
```

Second Test
We reject the null hypothesis due to the .004 P-Value.
```{r}
anova(model_3,model_1)
```

Third Test
We reject the null hypothesis due to the .0006 P-Value.
```{r}
anova(model_4,model_1)
```

#8.5
We start with an exploration of the data, and we see that IQb and IQf both appear roughly normally distributed. We see a correlation between IQf and IQb almost immediately. 
```{r}
ggpairs(twins)
```

Now we fit a simple model of IQf and IQb. 
```{r}
model <- lm(IQf ~ IQb,data=twins)
summary(model)
```

Now extract the residuals and look at the variance. It appears to be fairly constant, so we try a test for non-constant variance.
```{r}
twins$residuals <- predict(model) - twins$IQf
ggplot(twins,aes(x=IQb,y=residuals)) + geom_point() + geom_smooth()
ncvTest(model)
```


Now, we fit the model with C as a factor, and it appears class is not significant. IQb is very significant, and the model has an R-Square of .8 which suggests a large amount of the variation in IQf is explained by IQb. 
```{r}
model <- lm(IQf ~ IQb + C,data=twins)
summary(model)
```

We can use an F test as well to verify that IQb is significant, and we see we can reject the null nypothesis that there is no significance. 

```{r}
nh <- lm(IQf ~ 1,data=twins)
ah <- lm(IQf ~ IQb,data=twins)
anova(ah,nh)
```

Now we move onto C.

Let's test the model with and without C and see if we can reject the null hypothesis that class is not significant. 

We cannot reject the null hypothesis using an F test.  
```{r}
nh <- lm(IQf ~ IQb,data=twins)
ah <- lm(IQf ~ IQb + C,data=twins)
anova(ah,nh)
```


#8.6

#7.7.1
```{r}
ggplot(galtonpeas,aes(x=Parent,y=Progeny)) + geom_point()
```

##7.7.2
```{r}
weighted_regression = lm(formula = Progeny ~ Parent, data = galtonpeas, weights = 1/SD^2)
ggplot(galtonpeas,aes(x=Parent,y=Progeny)) + 
    geom_point() +
    geom_line(aes(y=predict(weighted_regression)))
```

##7.7.3

The intercept would be increased due to the decrease in the slope, and the variance would be increased due to the biased selection. 

##8.6.1

Without weights, we are estimating the mean of a group of peas of an unknown size, not the size of an individual pea. 
```{r}
unweighted_regression = lm(formula = Progeny ~ Parent, data = galtonpeas)
```

#8.7

```{r}
model_1 <- lm(Y ~ X1 + X2 + I(X1^2) + I(X2^2) + X1:X2, data=cakes)
param.names <- paste("b", 0:5, sep="")
x1.max <- "(b2*b5-2*b1*b4)/(4*b3*b4-b5^2)"
deltaMethod(model_1, x1.max,parameterNames=param.names)
```

#8.8

First let's fit the model and use the built in package. 
```{r}
model <- lm(Y ~ .,data=sniffer)
ncvTest(model)
```

Now we do the math manually and make return the p-value of the fitted model, which matches both the book and the test above. 

```{r}
score_test_fitted_values <- function(model){
  model_summary <-summary(model)
  rss <- residuals(model_summary, type="pearson")
  S.sq <-df.residual(model)*(model_summary$sigma)^2/sum(!is.na(rss))
  U <-(rss^2)/S.sq
  model_U <- lm(U~fitted.values(model))
  df<-1
  SS<-anova(model_U)$"Sum Sq"
  SS_2<-sum(SS)-SS[length(SS)]
  Chisq<-SS_2/2
  if (is.na(df)) {df <- coefficients(model_U)}
  1-pchisq(Chisq, df)
}

#Using the Fitted Values
score_test_fitted_values(model)
```

We can regenerate all the results in the table by changing the model for U. We can see they match the book after accounting for rounding. 

```{r}
score_test <- function(model,formula){
  model_summary <-summary(model)
  rss <- residuals(model_summary, type="pearson")
  S.sq <-df.residual(model)*(model_summary$sigma)^2/sum(!is.na(rss))
  U <-(rss^2)/S.sq
  model_U <- lm(as.formula(formula),data=model$model)
  df <- sum(!is.na(coefficients(model_U))) - 1
  SS<-anova(model_U)$"Sum Sq"
  SS_2<-sum(SS)-SS[length(SS)]
  Chisq<-SS_2/2
  if (is.na(df)) {df <- coefficients(model_U)}
  1-pchisq(Chisq, df)
}


#GasPres
score_test(model,formula="U ~ GasPres")
#TankTemp
score_test(model,formula="U ~ TankTemp")
#TankTemp,GasPres
score_test(model,formula="U ~ TankTemp + GasPres")
#TankTemp,GasTemp,TankPres,GasPres
score_test(model,formula="U ~ TankTemp + GasTemp + TankPres + GasPres")
```
